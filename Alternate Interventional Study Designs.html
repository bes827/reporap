
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Alternate Interventional Study Designs</title>
<style>

<style>
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: linear-gradient(135deg, #f0f4ff, #fafafa);
    color: #2c2c2c;
    padding: 40px;
}

/* Mindmap container */
.mindmap {
    max-width: 900px;
    margin: auto;
    font-size: 16px;
    line-height: 1.7;
}

.mindmap ul {
    margin: 0.5em 0 1em 1em;
    padding-left: 1.5em;
    list-style: disc;
    color: #555;
    font-size: 0.95em;
    font-weight: 400;
    line-height: 1.6;
}

.mindmap li::marker {
    color: #a855f7; /* prettier bullets */
}

.mindmap li {
    margin-bottom: 6px;
    padding-left: 4px;
}


/* Collapsible sections */
.mindmap details {
    border-left: 4px solid #8b5cf6;
    background: #ffffff;
    margin: 15px 0;
    padding: 16px 20px;
    border-radius: 16px;
    box-shadow: 0 4px 12px rgba(139, 92, 246, 0.12);
    transition: all 0.3s ease;
    position: relative;
}

/* Hover glow */
.mindmap details:hover {
    box-shadow: 0 6px 18px rgba(139, 92, 246, 0.2);
    background: linear-gradient(135deg, #ffffff, #f3f0ff);
}

/* Summary styling */
.mindmap summary {
    cursor: pointer;
    font-size: 1.15em;
    font-weight: 600;
    list-style: none;
    position: relative;
    padding-left: 28px;
    color: #4c1d95;
}

/* Custom arrow */
.mindmap summary::before {
    content: "▶";
    position: absolute;
    left: 0;
    top: 2px;
    transition: transform 0.3s ease;
    font-size: 1em;
    color: #7c3aed;
}

.mindmap details[open] > summary::before {
    transform: rotate(90deg);
}

/* Titles */
.mindmap summary strong {
    display: block;
    font-size: 1.3em;
    color: #4c1d95;
}

.mindmap summary em {
    font-style: normal;
    color: #6b21a8;
    font-size: 0.95em;
}

/* Description bullets */
.mindmap ul {
    padding-left: 22px;
    margin-top: 10px;
    margin-bottom: 12px;
}

.mindmap li {
    margin-bottom: 6px;
    font-size: 0.97em;
    color: #444;
    list-style-type: disc;
    position: relative;
    padding-left: 4px;
}

/* Nesting indent style */
.mindmap details > div > details {
    margin-left: 20px;
    border-color: #a855f7;
    background: #f9f5ff;
}

/* Fade-in effect */
.mindmap details[open] > div {
    animation: fadeIn 0.3s ease-in;
}

/* Description box */
.mindmap .desc-box {
    background: #fdfcff;
    border: 1px solid #e5d9fb;
    border-left: 4px solid #c084fc;
    padding: 4px 6px;
    margin: 12px 0 18px 0;
    border-radius: 12px;
    box-shadow: 0 1px 3px rgba(160, 104, 255, 0.06);
    transition: background 0.3s ease;
}

.mindmap .desc-box:hover {
    background: #f9f4ff;
}


button {
    background-color: #7c3aed;
    color: white;
    border: none;
    padding: 10px 16px;
    margin: 0 6px;
    font-size: 1em;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.3s ease;
}
button:hover {
    background-color: #6b21a8;
}


@keyframes fadeIn {
    from { opacity: 0; transform: translateY(-3px); }
    to { opacity: 1; transform: translateY(0); }
}


#level-controls button {
    background-color: rgba(124, 58, 237, 0.7); /* semi-transparent purple */
    color: white;
    border: none;
    padding: 8px 14px;
    margin: 0 6px;
    font-size: 1em;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.3s ease, transform 0.2s;
}

#level-controls button:hover {
    background-color: rgba(107, 33, 168, 0.85); /* slightly darker on hover */
    transform: scale(1.05);
}

#level-controls {
    position: fixed;
    bottom: 20px;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(124, 58, 237, 0.1);
    padding: 8px 14px;
    border-radius: 12px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    z-index: 9999;
    backdrop-filter: blur(6px);
    cursor: move; /* shows move cursor */
}

</style>




</style>
</head>
<body>
<div id="level-controls" onmousedown="dragElement(this)">
    <button onclick="setMindmapLevel(1)">Level 1</button>
    <button onclick="setMindmapLevel(2)">Level 2</button>
    <button onclick="setMindmapLevel(3)">Level 3</button>
</div>

<div class="mindmap">

    <div class="mindmap">
        
        <details>
            <summary><strong>Alternate Interventional Study Designs</strong></summary>
            <div>
                <ul><li>Source: Chapter 12</li><li>Authors: Deborah G. Grady, Steven R. Cummings, and Alison J. Huang</li></ul>
                
        <details>
            <summary><strong>Knowledge Test</strong></summary>
            <div>
                <ul><li>1. What is the key statistical challenge in a factorial trial design that can reduce its power if not accounted for?</li><li>2. In a noninferiority trial, what is the term for the pre-specified difference in efficacy that, if exceeded, would deem the new treatment inferior?</li><li>3. What type of trial design allows for pre-planned protocol changes, such as dropping ineffective treatment arms, based on interim analyses?</li><li>4. What is the primary advantage of a crossover design that allows it to use fewer participants than a parallel group trial?</li><li>5. What statistical phenomenon, where extreme measurements tend to move closer to the average on subsequent tests, is a major weakness of before-after study designs?</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Alternative Randomized Designs</strong></summary>
            <div>
                <ul><li>Study designs where the investigator introduces an intervention, but some aspects of the classic randomized trial are altered.</li></ul>
                
        <details>
            <summary><strong>Factorial Design</strong></summary>
            <div>
                <ul><li>Aims to answer ≥2 distinct research questions in a single study.</li><li>Participants are randomly assigned to one of ≥4 groups (e.g., Drug A + Drug B, Drug A + Placebo B, Placebo A + Drug B, Placebo A + Placebo B).</li></ul>
                
        <details>
            <summary><strong>Mechanism</strong></summary>
            <div>
                <ul><li>Analyzes the effect of one intervention by combining all participants who received it vs. all who did not, disregarding the other intervention.</li><li>This process is then repeated for the second intervention.</li></ul>
                
        <details>
            <summary><strong>Example: VITAL Trial</strong></summary>
            <div>
                <ul><li>Tested Vitamin D3 &amp; omega-3 fatty acids on cardiovascular events &amp; cancer risk.</li><li>Found neither intervention was beneficial.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Limitations</strong></summary>
            <div>
                <ul><li>Potential issues that can complicate the design and reduce its efficiency.</li></ul>
                
        <details>
            <summary><strong>Effect Modification</strong></summary>
            <div>
                <ul><li>The effect of one intervention differs depending on whether the other intervention was also received.</li><li>If present, requires separate analyses for subgroups, which ↓ statistical power.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Population Suitability</strong></summary>
            <div>
                <ul><li>The same target population must be appropriate for all interventions being tested.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Recruitment &amp; Adherence</strong></summary>
            <div>
                <ul><li>Managing multiple treatments may interfere with participant recruitment and adherence.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Active Control Trials</strong></summary>
            <div>
                <ul><li>The control group receives an active intervention, often the &#x27;standard of care&#x27;.</li><li>Also known as &#x27;comparative effectiveness trials&#x27;.</li></ul>
                
        <details>
            <summary><strong>Superiority Trial</strong></summary>
            <div>
                <ul><li>Aims to show a new treatment is superior to an established one.</li><li>Design and methods are similar to a placebo-controlled trial.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Equivalence &amp; Noninferiority Trials</strong></summary>
            <div>
                <ul><li>Goal: Establish a new therapy has similar efficacy to a standard one, but offers other advantages (e.g., ↑safety, ↓invasiveness, ↑ease of use).</li></ul>
                
        <details>
            <summary><strong>Statistical Approach</strong></summary>
            <div>
                <ul><li>Goal is to show the difference between treatments is not clinically meaningful.</li><li>Uses a confidence interval (CI) for the difference in effect between the new and standard treatments.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Noninferiority Margin (Delta or &#x27;Δ&#x27;)</strong></summary>
            <div>
                <ul><li>The pre-specified difference in efficacy that is considered clinically acceptable.</li><li>If the CI for the difference does not include Δ, noninferiority is established.</li></ul>
                
        <details>
            <summary><strong>Setting Δ</strong></summary>
            <div>
                <ul><li>Based on statistical considerations and clinical judgment.</li><li>Can be based on meta-analyses of standard treatment vs. placebo or results of a high-quality RCT.</li><li>Must be set to ensure the new therapy is still more effective than placebo.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Key Considerations &amp; Pitfalls</strong></summary>
            <div>
                <ul><li>Important factors to consider in the design and interpretation of noninferiority trials.</li></ul>
                
        <details>
            <summary><strong>Sample Size</strong></summary>
            <div>
                <ul><li>Usually larger than placebo-controlled trials because Δ is typically smaller than the expected difference between a new treatment and placebo.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Assay Sensitivity</strong></summary>
            <div>
                <ul><li>Requires strong prior evidence that the established treatment is effective.</li><li>The noninferiority trial design should be as similar as possible to the trials that established the standard treatment&#x27;s efficacy.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Risk of Poor Study Quality</strong></summary>
            <div>
                <ul><li>Any issue that ↓ the efficacy of the standard treatment (e.g., nonadherence, loss to follow-up) makes it easier for a new, less effective treatment to appear noninferior.</li><li>A &#x27;noninferior&#x27; finding could just reflect a poorly conducted study.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Adaptive Designs</strong></summary>
            <div>
                <ul><li>Allows for pre-planned changes to the trial protocol based on interim analyses of results.</li></ul>
                
        <details>
            <summary><strong>Mechanism &amp; Rules</strong></summary>
            <div>
                <ul><li>Rules for how changes can be made must be established *before* the trial begins.</li><li>Interim analyses and design change considerations should be done by an independent data monitoring board to prevent bias.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Possible Adaptations</strong></summary>
            <div>
                <ul><li>Stopping enrollment to ineffective treatment arms (e.g., lower doses).</li><li>Modifying sample size or trial duration if interim results suggest the effect size or outcome rate differs from original assumptions.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Feasibility</strong></summary>
            <div>
                <ul><li>Only feasible for interventions with outcomes that can be measured and analyzed early enough to make design changes possible.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Platform Trials</strong></summary>
            <div>
                <ul><li>A type of adaptive trial with a single master protocol to evaluate multiple interventions, simultaneously or sequentially.</li></ul>
                
        <details>
            <summary><strong>Advantages</strong></summary>
            <div>
                <ul><li>Can identify efficacious interventions more quickly and with fewer resources.</li><li>Allows adding/dropping interventions without creating a new trial infrastructure.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Example: ACTT-1</strong></summary>
            <div>
                <ul><li>Platform trial for COVID-19 treatments.</li><li>Remdesivir was found to shorten recovery time vs. placebo.</li><li>The platform was designed to drop the placebo arm once an effective treatment was found and continue testing other agents.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Bayesian Trials</strong></summary>
            <div>
                <ul><li>Incorporates prior evidence (e.g., from previous studies) into the trial&#x27;s design and analysis.</li><li>Contrasts with standard &#x27;frequentist&#x27; trials.</li></ul>
                
        <details>
            <summary><strong>Mechanism</strong></summary>
            <div>
                <ul><li>Applies a &#x27;prior probability&#x27; that the treatment is effective to the analysis of the current trial&#x27;s results.</li></ul>
                
        <details>
            <summary><strong>Example</strong></summary>
            <div>
                <ul><li>Frequentist trial: 20% risk reduction, P=0.09 → &#x27;not statistically significant&#x27;.</li><li>Bayesian trial: Incorporates prior studies showing a 25% risk reduction → might estimate a 99% probability that the treatment reduces risk by ≥20%.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Characteristics</strong></summary>
            <div>
                <ul><li>Often use a flexible number of participants without a fixed sample size.</li><li>Do not use traditional stopping rules based on P values adjusted for multiple looks.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Crossover Designs</strong></summary>
            <div>
                <ul><li>Participants are randomly assigned to a sequence of treatments (e.g., Intervention A then Control, or Control then Intervention A).</li><li>Each participant serves as their own control.</li></ul>
                
        <details>
            <summary><strong>Advantages</strong></summary>
            <div>
                <ul><li>↑ Statistical power due to paired, within-group analysis.</li><li>Requires fewer participants than parallel group trials.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Disadvantages</strong></summary>
            <div>
                <ul><li>Doubles the duration of the study.</li><li>↑ Expense due to more frequent outcome measurements.</li><li>Potential for &#x27;carryover effects&#x27;: residual influence of the first intervention after it has been stopped.</li></ul>
                
        <details>
            <summary><strong>Mitigation: Washout Period</strong></summary>
            <div>
                <ul><li>An untreated period between interventions to allow the outcome to return to baseline.</li><li>It can be difficult to know if all carryover effects have been eliminated.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Best Suited For</strong></summary>
            <div>
                <ul><li>Conditions where the outcome responds rapidly and reversibly to an intervention.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Wait-List Designs</strong></summary>
            <div>
                <ul><li>A variation of the crossover design where participants are randomized to immediate intervention or to a wait-list control group that receives the intervention later.</li></ul>
                
        <details>
            <summary><strong>Appropriate Situations</strong></summary>
            <div>
                <ul><li>When the intervention cannot be blinded and is highly desirable (improves recruitment).</li><li>When an entity (e.g., hospital, government) has decided all members should eventually receive the intervention for political or fairness reasons.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Analysis</strong></summary>
            <div>
                <ul><li>Allows for a randomized comparison (immediate vs. wait-list groups).</li><li>Allows for a pooled within-group comparison (before vs. after intervention for all participants).</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Limitations</strong></summary>
            <div>
                <ul><li>Outcome must occur in a short enough period to keep the waiting period from being too long.</li><li>Providing the intervention to the control group prolongs follow-up and ↑ cost.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>N-of-1 Designs (Single Patient Trials)</strong></summary>
            <div>
                <ul><li>A crossover trial that enrolls only one person.</li><li>Aims to answer clinical questions about effectiveness or adverse effects in a specific individual patient.</li></ul>
                
        <details>
            <summary><strong>Mechanism</strong></summary>
            <div>
                <ul><li>Patient is randomly assigned for a set period to a blinded treatment or placebo, then crosses over to the alternative.</li><li>Multiple crossovers provide stronger evidence.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Advantages</strong></summary>
            <div>
                <ul><li>May answer the efficacy question for a specific patient, rather than an average effect across a group.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Limitations</strong></summary>
            <div>
                <ul><li>Best suited for chronic or recurrent symptomatic conditions where the outcome responds and resolves quickly.</li><li>Carryover effects are a concern; washout periods can be used.</li><li>Requires patient understanding and willingness; blinding is crucial.</li><li>Logistically difficult for an individual clinician to conduct without support (e.g., a research pharmacy).</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Cluster Randomized Designs</strong></summary>
            <div>
                <ul><li>Naturally occurring groups or &#x27;clusters&#x27; of participants (e.g., clinics, schools, teams) are randomly assigned to interventions, rather than individuals.</li></ul>
                
        <details>
            <summary><strong>Rationale</strong></summary>
            <div>
                <ul><li>May be more feasible and cost-effective than randomizing individuals.</li><li>Avoids &#x27;contamination&#x27; of the control group.</li><li>Necessary for interventions applied at a group level (e.g., quality improvement initiatives).</li></ul>
                
        <details>
            <summary><strong>Example</strong></summary>
            <div>
                <ul><li>120 college baseball teams randomized to a spit-tobacco cessation intervention.</li><li>Result: 35% of players quit in intervention colleges vs. 16% in control colleges.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Statistical Considerations</strong></summary>
            <div>
                <ul><li>The unit of randomization is the cluster, not the individual.</li><li>Effective sample size is smaller than the total number of participants.</li><li>Power is higher with a large number of small clusters vs. a small number of large clusters.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Potential Problems</strong></summary>
            <div>
                <ul><li>Imbalance in baseline characteristics between arms is more likely with fewer randomized units (clusters).</li><li>Sample size estimation and data analysis are more complicated than for individual randomization.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Stepped Wedge Designs</strong></summary>
            <div>
                <ul><li>A variation of the cluster randomized design where clusters are randomized to the *order* in which they begin the intervention.</li><li>By the end of the trial, all clusters have received the intervention.</li></ul>
                
        <details>
            <summary><strong>Mechanism</strong></summary>
            <div>
                <ul><li>Trial begins with a baseline period (no clusters receive intervention).</li><li>At set time intervals (&#x27;steps&#x27;), randomly selected clusters begin the intervention and continue it until the trial ends.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Advantages</strong></summary>
            <div>
                <ul><li>More politically or culturally acceptable as all participants eventually receive the intervention.</li><li>Feasible when logistical constraints prevent rolling out a complex intervention all at once.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Analysis</strong></summary>
            <div>
                <ul><li>Allows for both between-cluster comparisons (intervention vs. control at the same time point) and within-cluster comparisons (before vs. after intervention).</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Limitations</strong></summary>
            <div>
                <ul><li>Temporal Confounding: Control data are collected earlier than intervention data, so changes over time (e.g., seasonal effects) can confound results.</li><li>Sample Size: May require a much larger sample size than individually randomized trials.</li><li>Complexity: Trials are often large, complex, and require complicated analysis.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Nonrandom Interventional Designs</strong></summary>
            <div>
                <ul><li>Also called &#x27;quasi-experimental&#x27; designs.</li><li>Investigator designs and implements an intervention but does not use random assignment.</li><li>Far less effective than randomized trials in controlling for confounding variables.</li></ul>
                
        <details>
            <summary><strong>Key Issues &amp; Pitfalls</strong></summary>
            <div>
                <ul><li>Fundamental weaknesses compared to randomized designs.</li></ul>
                
        <details>
            <summary><strong>Confounding</strong></summary>
            <div>
                <ul><li>High risk of unmeasured confounding.</li><li>Apparent benefits of intervention are often greater in nonrandomized studies compared to RCTs of the same question.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Pseudorandomization</strong></summary>
            <div>
                <ul><li>Allocation by a predictable mechanism (e.g., even/odd hospital record number).</li><li>Does not guarantee baseline comparability and is open to manipulation by staff.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Ethical Considerations</strong></summary>
            <div>
                <ul><li>Often chosen under the mistaken belief they are more ethical.</li><li>However, the ethical basis for a trial is &#x27;equipoise&#x27; (genuine uncertainty), which justifies randomization.</li><li>Nonrandomized studies are less likely to produce a correct result.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Nonrandomized Within-Group Designs</strong></summary>
            <div>
                <ul><li>Designs that compare outcomes within a single group before and after an intervention.</li></ul>
                
        <details>
            <summary><strong>Before-After (Pre-Post) Designs</strong></summary>
            <div>
                <ul><li>Compares an outcome before and after an intervention is applied.</li><li>Essentially a single-arm trial with no concurrent control group.</li></ul>
                
        <details>
            <summary><strong>Weaknesses</strong></summary>
            <div>
                <ul><li>Causal inference is substantially weakened by several factors.</li></ul>
                
        <details>
            <summary><strong>Temporal Effects</strong></summary>
            <div>
                <ul><li>Seasonal changes, concurrent policy changes, or other events over time might affect the outcome, independent of the intervention.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Regression to the Mean</strong></summary>
            <div>
                <ul><li>The tendency for a measurement that is extreme on first measure to be closer to the average on a second measure.</li><li>An intervention may appear effective when the change is just due to this statistical phenomenon.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Maturation Effect</strong></summary>
            <div>
                <ul><li>People, staff, and clinicians tend to learn and improve over time without any specific intervention.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Strengthening Causal Inference</strong></summary>
            <div>
                <ul><li>Making several outcome measurements before the intervention to ensure a stable baseline.</li><li>Adding a &#x27;falsification test&#x27;: measuring an outcome that should *not* change due to the intervention to see if it also changes.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Interrupted Time Series Designs</strong></summary>
            <div>
                <ul><li>Requires multiple measurements before and after the intervention to estimate trends.</li><li>Assumes the pre-intervention trend would have continued unchanged without the intervention.</li></ul>
                
        <details>
            <summary><strong>Mechanism</strong></summary>
            <div>
                <ul><li>Determines if there was a change in the level (immediate effect) or trend (slope) of the outcome after the intervention.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Requirements</strong></summary>
            <div>
                <ul><li>Conventionally, at least 3 measurements are needed before and after the intervention to calculate trends.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Weaknesses</strong></summary>
            <div>
                <ul><li>Prone to confounding by seasonality, changes in data collection, or other simultaneous changes in policy or practice.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Nonrandomized Between-Group Designs</strong></summary>
            <div>
                <ul><li>These designs add a nonrandomized control group to strengthen causal inference.</li></ul>
                
        <details>
            <summary><strong>Controlled Before-After Study</strong></summary>
            <div>
                <ul><li>Measures outcomes in two non-equivalent groups (intervention and control) concurrently before and after the intervention.</li></ul>
                
        <details>
            <summary><strong>Analysis: &#x27;Difference-in-Differences&#x27;</strong></summary>
            <div>
                <ul><li>The main outcome is the difference in the *change* in outcomes between the intervention and control groups.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Advantage</strong></summary>
            <div>
                <ul><li>If both groups experience the same temporal changes, it is more plausible that any difference between groups isdue to the intervention.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Weakness</strong></summary>
            <div>
                <ul><li>Regression to the mean is still a major problem, especially if the intervention group was selected due to a high level of disease that did not occur in the control group.</li><li>Lack of randomization can result in confounding differences between groups.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Controlled Interrupted Time Series</strong></summary>
            <div>
                <ul><li>Adds a nonrandomized control group to an interrupted time series design.</li><li>The outcome is the difference between groups in the change in level or trend of the outcome.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Summary</strong></summary>
            <div>
                <ul><li>Key takeaways on alternate interventional study designs.</li></ul>
                
        <details>
            <summary><strong>1. Factorial Randomized Trial</strong></summary>
            <div>
                <ul><li>Aims to answer ≥2 research questions in a single trial.</li><li>Limitation: Effect modification can reduce power.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>2. Noninferiority Trials</strong></summary>
            <div>
                <ul><li>Compares a new intervention to an established one to see if efficacy does not differ by more than a predetermined amount.</li><li>Appropriate when a standard of care exists; typically requires a larger sample size than placebo-controlled trials.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>3. Adaptive Designs</strong></summary>
            <div>
                <ul><li>Allows protocol changes based on interim analyses, potentially increasing efficiency.</li><li>Platform trials use a single master protocol to evaluate multiple interventions, identifying effective treatments more quickly.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>4. Crossover Design</strong></summary>
            <div>
                <ul><li>Each participant serves as their own control, receiving both intervention and control in a random sequence.</li><li>↑ statistical power and requires fewer participants.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>5. Wait-List Trial</strong></summary>
            <div>
                <ul><li>Participants are randomized to immediate intervention or a wait-list control group that receives the intervention later.</li><li>Improves feasibility for desirable interventions.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>6. N-of-1 Designs</strong></summary>
            <div>
                <ul><li>Crossover trials enrolling only one person.</li><li>Aims to determine effectiveness or adverse effects for an individual patient.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>7. Cluster Randomized Trial</strong></summary>
            <div>
                <ul><li>Groups (clusters) of participants are randomized instead of individuals.</li><li>More feasible and cost-effective in certain settings; avoids contamination.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>8. Stepped Wedge Trial</strong></summary>
            <div>
                <ul><li>Clusters are randomized to the *order* in which they begin the intervention.</li><li>Appropriate when fairness or logistics dictate that all participants eventually receive the intervention.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>9. Nonrandomized Within-Group Designs</strong></summary>
            <div>
                <ul><li>Used when randomized trials are not possible; compare outcomes within a group before and after an intervention.</li></ul>
                
        <details>
            <summary><strong>a. Before-After Designs</strong></summary>
            <div>
                <ul><li>Measure an outcome before and after an intervention is applied.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>b. Interrupted Time Series Designs</strong></summary>
            <div>
                <ul><li>Use multiple measurements before and after the intervention to account for pre-existing trends.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>10. Nonrandomized Between-Group Designs</strong></summary>
            <div>
                <ul><li>Add a nonrandomized control group to before-after or interrupted time series studies.</li><li>The main outcome is the &#x27;difference-in-differences&#x27; to strengthen causal inference.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
    </div>
    
</div>


<script>
function setMindmapLevel(level) {
    const allDetails = document.querySelectorAll('.mindmap details');

    // Close all
    allDetails.forEach(detail => detail.removeAttribute('open'));

    // Open based on depth
    allDetails.forEach(detail => {
        let depth = 0;
        let parent = detail.parentElement;
        while (parent && parent.tagName !== 'BODY') {
            if (parent.tagName === 'DETAILS') depth++;
            parent = parent.parentElement;
        }
        if (depth < level) detail.setAttribute('open', '');
    });
}

// Automatically open to level 1 on page load
window.addEventListener('DOMContentLoaded', () => {
    setMindmapLevel(1);
});

function dragElement(elmnt) {
    let pos1 = 0, pos2 = 0, pos3 = 0, pos4 = 0;

    const onMouseDown = (e) => {
        e.preventDefault();
        pos3 = e.clientX;
        pos4 = e.clientY;
        document.onmouseup = closeDragElement;
        document.onmousemove = elementDrag;
    };

    const elementDrag = (e) => {
        e.preventDefault();
        pos1 = pos3 - e.clientX;
        pos2 = pos4 - e.clientY;
        pos3 = e.clientX;
        pos4 = e.clientY;
        elmnt.style.top = (elmnt.offsetTop - pos2) + "px";
        elmnt.style.left = (elmnt.offsetLeft - pos1) + "px";
        elmnt.style.transform = "none"; // cancel centering transform
        elmnt.style.bottom = "auto"; // cancel fixed bottom
    };

    const closeDragElement = () => {
        document.onmouseup = null;
        document.onmousemove = null;
    };

    onMouseDown(event);
}
</script>


</body>
</html>
