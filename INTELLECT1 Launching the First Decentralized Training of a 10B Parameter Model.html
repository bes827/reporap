
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>INTELLECT–1: Launching the First Decentralized Training of a 10B Parameter Model</title>
<style>

<style>
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: linear-gradient(135deg, #f0f4ff, #fafafa);
    color: #2c2c2c;
    padding: 40px;
}

/* Mindmap container */
.mindmap {
    max-width: 900px;
    margin: auto;
    font-size: 16px;
    line-height: 1.7;
}

.mindmap ul {
    margin: 0.5em 0 1em 1em;
    padding-left: 1.5em;
    list-style: disc;
    color: #555;
    font-size: 0.95em;
    font-weight: 400;
    line-height: 1.6;
}

.mindmap li::marker {
    color: #a855f7; /* prettier bullets */
}

.mindmap li {
    margin-bottom: 6px;
    padding-left: 4px;
}


/* Collapsible sections */
.mindmap details {
    border-left: 4px solid #8b5cf6;
    background: #ffffff;
    margin: 15px 0;
    padding: 16px 20px;
    border-radius: 16px;
    box-shadow: 0 4px 12px rgba(139, 92, 246, 0.12);
    transition: all 0.3s ease;
    position: relative;
}

/* Hover glow */
.mindmap details:hover {
    box-shadow: 0 6px 18px rgba(139, 92, 246, 0.2);
    background: linear-gradient(135deg, #ffffff, #f3f0ff);
}

/* Summary styling */
.mindmap summary {
    cursor: pointer;
    font-size: 1.15em;
    font-weight: 600;
    list-style: none;
    position: relative;
    padding-left: 28px;
    color: #4c1d95;
}

/* Custom arrow */
.mindmap summary::before {
    content: "▶";
    position: absolute;
    left: 0;
    top: 2px;
    transition: transform 0.3s ease;
    font-size: 1em;
    color: #7c3aed;
}

.mindmap details[open] > summary::before {
    transform: rotate(90deg);
}

/* Titles */
.mindmap summary strong {
    display: block;
    font-size: 1.3em;
    color: #4c1d95;
}

.mindmap summary em {
    font-style: normal;
    color: #6b21a8;
    font-size: 0.95em;
}

/* Description bullets */
.mindmap ul {
    padding-left: 22px;
    margin-top: 10px;
    margin-bottom: 12px;
}

.mindmap li {
    margin-bottom: 6px;
    font-size: 0.97em;
    color: #444;
    list-style-type: disc;
    position: relative;
    padding-left: 4px;
}

/* Nesting indent style */
.mindmap details > div > details {
    margin-left: 20px;
    border-color: #a855f7;
    background: #f9f5ff;
}

/* Fade-in effect */
.mindmap details[open] > div {
    animation: fadeIn 0.3s ease-in;
}

/* Description box */
.mindmap .desc-box {
    background: #fdfcff;
    border: 1px solid #e5d9fb;
    border-left: 4px solid #c084fc;
    padding: 4px 6px;
    margin: 12px 0 18px 0;
    border-radius: 12px;
    box-shadow: 0 1px 3px rgba(160, 104, 255, 0.06);
    transition: background 0.3s ease;
}

.mindmap .desc-box:hover {
    background: #f9f4ff;
}


button {
    background-color: #7c3aed;
    color: white;
    border: none;
    padding: 10px 16px;
    margin: 0 6px;
    font-size: 1em;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.3s ease;
}
button:hover {
    background-color: #6b21a8;
}


@keyframes fadeIn {
    from { opacity: 0; transform: translateY(-3px); }
    to { opacity: 1; transform: translateY(0); }
}


#level-controls button {
    background-color: rgba(124, 58, 237, 0.7); /* semi-transparent purple */
    color: white;
    border: none;
    padding: 8px 14px;
    margin: 0 6px;
    font-size: 1em;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.3s ease, transform 0.2s;
}

#level-controls button:hover {
    background-color: rgba(107, 33, 168, 0.85); /* slightly darker on hover */
    transform: scale(1.05);
}

#level-controls {
    position: fixed;
    bottom: 20px;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(124, 58, 237, 0.1);
    padding: 8px 14px;
    border-radius: 12px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    z-index: 9999;
    backdrop-filter: blur(6px);
    cursor: move; /* shows move cursor */
}

</style>




</style>
</head>
<body>
<div id="level-controls" onmousedown="dragElement(this)">
    <button onclick="setMindmapLevel(1)">Level 1</button>
    <button onclick="setMindmapLevel(2)">Level 2</button>
    <button onclick="setMindmapLevel(3)">Level 3</button>
</div>

<div class="mindmap">

    <div class="mindmap">
        
        <details>
            <summary><strong>INTELLECT–1: Launching the First Decentralized Training of a 10B Parameter Model</strong></summary>
            <div>
                <ul><li>Authors: Johannes, Sami, Jackmin, Vincent</li><li>Source: Prime Intellect Announcements</li><li>Publication Date: October 11, 2024</li><li>Focus: First decentralized training run of a 10-billion-parameter AI model.</li><li>Goal: Advance open-source AGI by enabling global compute contributions.</li></ul>
                
        <details>
            <summary><strong>Knowledge Test</strong></summary>
            <div>
                <ul><li>1. What is the primary goal of decentralized AI model training as championed by Prime Intellect?</li><li>2. Which DeepMind method was open-sourced and scaled by Prime Intellect to enable globally distributed AI training?</li><li>3. How much can pseudo-gradient quantization reduce bandwidth requirements in Prime&#x27;s framework when combined with outer optimizer synchronization?</li><li>4. What is the key innovation in Prime&#x27;s ElasticDeviceMesh for fault-tolerant training compared to standard PyTorch distributed DeviceMesh?</li><li>5. Which high-quality open-source dataset forms the largest portion of the data mix for INTELLECT-1&#x27;s 10B parameter model training?</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>INTELLECT-1 Overview</strong></summary>
            <div>
                <ul><li>First decentralized training of a 10B-parameter model.</li><li>Scales OpenDiLoCo by 10x from 1B to 10B parameters; ≈25x from original research.</li><li>Aims to collaboratively train frontier open foundation models: language, agents, scientific models.</li></ul>
                
        <details>
            <summary><strong>Motivation for Decentralization</strong></summary>
            <div>
                <ul><li>Ensure AGI is open-source, transparent, accessible.</li><li>Prevent control by few centralized entities.</li><li>Accelerate human progress.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Launch Partners &amp; Contributors</strong></summary>
            <div>
                <ul><li>Leading open-source AI players contribute compute.</li></ul>
                
        <details>
            <summary><strong>Key Partners</strong></summary>
            <div>
                <ul><li>Hugging Face, SemiAnalysis, Arcee, Hyperbolic, Olas, Akash, Schelling AI.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>How to Contribute Compute</strong></summary>
            <div>
                <ul><li>Anyone can contribute resources to advance open-source AI.</li></ul>
                
        <details>
            <summary><strong>Platform Access</strong></summary>
            <div>
                <ul><li>Dashboard: https://app.primeintellect.ai/intelligence (monitor training, contribute compute).</li><li>Code: https://github.com/PrimeIntellect-ai/Prime.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Paradigm Shift: Decentralized Training</strong></summary>
            <div>
                <ul><li>Addresses challenge of efficiently training 10B+ parameter models across globally distributed workers.</li><li>OpenDiLoCo broke 1B parameter barrier; INTELLECT-1 reaches new scale.</li></ul>
                
        <details>
            <summary><strong>DiLoCo Method</strong></summary>
            <div>
                <ul><li>Enables AI model training on &#x27;islands&#x27; of poorly connected devices.</li><li>Allows data parallel training on different islands.</li><li>Requires synchronization of pseudo-gradients only every few hundred steps.</li><li>Significantly ↓ communication frequency (up to 500x) → ↓ bandwidth requirements.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Prime: Decentralized Training Framework</strong></summary>
            <div>
                <ul><li>Improved distributed training framework since initial open-source release.</li></ul>
                
        <details>
            <summary><strong>Algorithmic Progress</strong></summary>
            <div>
                <ul><li>Ablations on OpenDiLoCo ↓ communication requirements.</li></ul>
                
        <details>
            <summary><strong>Quantization Experiments</strong></summary>
            <div>
                <ul><li>Pseudo-gradient quantization ↓ bandwidth requirements by up to 2000x.</li><li>Method: Combines int8 quantization of pseudo-gradients w/ outer optimizer synchronization every 500 steps.</li><li>Effectiveness: Effective at smaller scales; scaling to larger models.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Scalable Decentralized Training Framework</strong></summary>
            <div>
                <ul><li>Addresses engineering &amp; research challenge of fault-tolerant training across distributed data centers.</li></ul>
                
        <details>
            <summary><strong>Prime Framework Release</strong></summary>
            <div>
                <ul><li>New framework for fault-tolerant training.</li><li>Supports dynamic on-/off-ramping of compute resources.</li><li>Optimizes communication &amp; routing across global GPU network.</li><li>Foundation for open-source tech stack; supports various decentralized training algorithms.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Key Features of Prime</strong></summary>
            <div>
                <ul><li>Core functionalities enabling robust, efficient decentralized training.</li></ul>
                
        <details>
            <summary><strong>ElasticDeviceMesh for Fault Tolerant Training</strong></summary>
            <div>
                <ul><li>New distributed abstraction.</li><li>Encapsulates dynamic global process groups for fault-tolerant internet communication.</li><li>Local process groups for communication within node/datacenter.</li><li>Manages resizing of global process groups when nodes join/leave.</li><li>Unlike standard `torch distributed DeviceMesh` which crashes &amp; requires cold restart.</li><li>Uses heartbeat mechanism to discover dead nodes &amp; remove them.</li><li>Crashing nodes attempt &#x27;deathrattle&#x27; to fail heartbeat quickly.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Asynchronous Distributed Checkpointing</strong></summary>
            <div>
                <ul><li>Addresses expensive checkpointing (up to 20 min) blocking main training.</li><li>Method: Checkpoint to `/dev/shm` (RAM-backed filesystem) first for speed.</li><li>Unblocks main training process once checkpoint in `/dev/shm`.</li><li>Two subprocesses asynchronously copy checkpoint from `/dev/shm` to disk &amp; upload remotely.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Live Checkpoint Recovery</strong></summary>
            <div>
                <ul><li>Enables joining nodes to get recent model/optimizer state mid-training.</li><li>Requirement: Must complete operation between two outer steps to avoid stale checkpoint.</li><li>Method: Joining nodes request checkpoints from peers (hosting sidecar HTTP server @ `/dev/shm`).</li><li>After download &amp; initialization, joining node skips inner steps &amp; joins outer step w/ zero pseudo-gradients.</li><li>Prevents stalling existing nodes; maintains cluster compute utilization.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Custom Int8 All-Reduce Kernel</strong></summary>
            <div>
                <ul><li>Int8 quantization on pseudo-gradients w/o loss curve impact.</li><li>Effect: ↓ payload size of each outer step all-reduce by 4x (int8 vs fp32).</li><li>Challenge: Need to accumulate reduce in fp32; dequantizing/re-quantizing intermediate results not supported by standard libraries.</li><li>Solution: Implemented custom fully pipelined ring-reduce kernel in C++ (JIT compiled via `torch` library).</li><li>Optimization: Custom multithreaded `uint8` ops in C++ for quantization/dequantization.</li><li>Result: ↑ quantization speed by &gt;60x; addresses `torch` ops being too slow for 4 Gbps bandwidth.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Maximizing Bandwidth Utilization</strong></summary>
            <div>
                <ul><li>Strategies to improve network transfer speeds.</li><li>Methods:</li><li>- Sharding DiLoCo pseudo-gradients in a node: ↑ network bandwidth utilization by opening multiple connections.</li><li>- Result: ↑ transfer speed by 8x on some nodes.</li><li>- VPN technology: Optimizes peer-to-peer connections; mitigates poor/unstable public IP forward bandwidth.</li><li>- Result: ↑ bandwidth utilization between nodes in similar data centers by up to 40x.</li><li>- Achieved up to 4Gb/s connections between data centers across the US.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>PyTorch FSDP2 / DTensor ZeRO-3 Implementation</strong></summary>
            <div>
                <ul><li>Shard model weights, gradients, optimizer states between intra-node GPUs.</li><li>Purpose: Fit 10B model training within memory resources.</li><li>Method: `fully_shard` API from PyTorch FSDP2.</li><li>Wraps model parameters as DTensors; registers hooks for all-gather &amp; reduce-scatter.</li><li>FSDP2 optimizes collectives by bucketing parameters into `FSDPParamGroups`.</li><li>Result: Executes collectives on larger tensors; ↑ protocol-to-payload ratio; ↑ overlap from pipelining.</li><li>Applies same bucketing trick for pseudo-gradients.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>CPU Off-Loading</strong></summary>
            <div>
                <ul><li>DiLoCo optimizer does not add GPU overhead.</li><li>Method: All tensors for DiLoCo optimizer offloaded to CPU memory.</li><li>Rationale: Global sync every hundreds of steps → reduced speed of copying/calculating pseudo-gradient on CPU is negligible vs. inner step execution time.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Training Performance Summary</strong></summary>
            <div>
                <ul><li>INTELLECT-1 trains at 10B parameter scale w/ 98% compute utilization across distributed workers.</li><li>Details:</li><li>- Synchronization: Every 100 steps.</li><li>- Duration: ≈40 minutes on islands of 8xH100 nodes.</li><li>- Pseudo-gradient Quantization: int8 → ↓ communication requirements by 400x.</li><li>- All-reduce Sync Time: &lt;1 minute using new framework.</li><li>- Communication Overhead: 1-2% of total training time.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>INTELLECT-1 Model Details</strong></summary>
            <div>
                <ul><li>Specifics of the 10B parameter model being trained.</li></ul>
                
        <details>
            <summary><strong>Architecture</strong></summary>
            <div>
                <ul><li>Based on Llama-3 architecture.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Dataset</strong></summary>
            <div>
                <ul><li>Extensively trained on Fineweb-Edu by Hugging Face (high-quality open-source dataset).</li></ul>
                
        <details>
            <summary><strong>Curated Data Mix</strong></summary>
            <div>
                <ul><li>55% Fineweb-edu</li><li>20% DLCM</li><li>20% Stack v2</li><li>5% OpenWebMath</li><li>Preprocessing: Pre-shuffled datasets by random sampling from 12 streaming iterators &amp; resharding.</li><li>Location: Pre-shuffled datasets on Hugging Face Hub.</li><li>Total Tokens: &gt;6 trillion tokens (processed w/ Llama-3 tokenizer).</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Learning Rate Scheduler</strong></summary>
            <div>
                <ul><li>WSD learning rate scheduler.</li><li>Method: Maintains constant learning rate after initial warm-up phase.</li><li>Benefit: Offers flexibility in number of tokens trainable based on compute contributions.</li><li>Future Plan: Cool-down phase w/ high-quality dataset + post-training optimizations towards end of training.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Next Steps &amp; Roadmap</strong></summary>
            <div>
                <ul><li>Future plans for scaling decentralized training.</li></ul>
                
        <details>
            <summary><strong>Scaling Models</strong></summary>
            <div>
                <ul><li>Scale to larger, more powerful open frontier models.</li><li>Domains: Scientific, reasoning, coding.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Compute Contribution System</strong></summary>
            <div>
                <ul><li>Develop system for anyone to contribute own compute resources.</li><li>Feature: Proof mechanisms to ensure secure, verifiable contributions.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>Decentralized Training Initiation Framework</strong></summary>
            <div>
                <ul><li>Create framework for anyone to initiate a decentralized training run.</li><li>Feature: Open for contributions from others.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Call to Action</strong></summary>
            <div>
                <ul><li>Invitation to join efforts in building open, decentralized AI.</li><li>Rationale: Open-source AI counters centralization risks; requires coordinated compute, talent, capital to compete w/ closed-source labs.</li></ul>
                
        <details>
            <summary><strong>Engagement Opportunities</strong></summary>
            <div>
                <ul><li>Apply for open roles (for ambitious individuals).</li><li>Collaborate on AI model initiatives &amp; open-source frameworks.</li><li>Contribute compute &amp; earn ownership in state-of-the-art AI models.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
        <details>
            <summary><strong>Prime Intellect Initiatives</strong></summary>
            <div>
                <ul><li>Other related programs and releases by Prime Intellect.</li></ul>
                
        <details>
            <summary><strong>Environments Hub</strong></summary>
            <div>
                <ul><li>Scaling open-source environments program to be global hub for open evals &amp; RL environments.</li><li>Commitment: Hundreds of thousands of $ in grants.</li><li>Goal: Accelerate open superintelligence.</li><li>Community Hub: Open, community-powered platform for RL environments.</li><li>Role of Environments: Define world, rules, feedback loop (state, action, reward) for AI learning.</li><li>Impact: Until now, fragmented, closed, hard to share.</li></ul>
                
            </div>
        </details>
        
        <details>
            <summary><strong>SYNTHETIC-2 Release</strong></summary>
            <div>
                <ul><li>Open dataset of four million verified reasoning traces.</li><li>Scope: Most comprehensive set of complex reinforcement learning tasks &amp; verifiers released to date.</li><li>Generation: Collaboratively generated by compute contributors globally via pipeline-parallel decentralized inference.</li><li>Scale: Over 1,250 GPUs joined in 3 days (4090s to H200s) to create data.</li></ul>
                
            </div>
        </details>
        
            </div>
        </details>
        
            </div>
        </details>
        
    </div>
    
</div>


<script>
function setMindmapLevel(level) {
    const allDetails = document.querySelectorAll('.mindmap details');

    // Close all
    allDetails.forEach(detail => detail.removeAttribute('open'));

    // Open based on depth
    allDetails.forEach(detail => {
        let depth = 0;
        let parent = detail.parentElement;
        while (parent && parent.tagName !== 'BODY') {
            if (parent.tagName === 'DETAILS') depth++;
            parent = parent.parentElement;
        }
        if (depth < level) detail.setAttribute('open', '');
    });
}

// Automatically open to level 1 on page load
window.addEventListener('DOMContentLoaded', () => {
    setMindmapLevel(1);
});

function dragElement(elmnt) {
    let pos1 = 0, pos2 = 0, pos3 = 0, pos4 = 0;

    const onMouseDown = (e) => {
        e.preventDefault();
        pos3 = e.clientX;
        pos4 = e.clientY;
        document.onmouseup = closeDragElement;
        document.onmousemove = elementDrag;
    };

    const elementDrag = (e) => {
        e.preventDefault();
        pos1 = pos3 - e.clientX;
        pos2 = pos4 - e.clientY;
        pos3 = e.clientX;
        pos4 = e.clientY;
        elmnt.style.top = (elmnt.offsetTop - pos2) + "px";
        elmnt.style.left = (elmnt.offsetLeft - pos1) + "px";
        elmnt.style.transform = "none"; // cancel centering transform
        elmnt.style.bottom = "auto"; // cancel fixed bottom
    };

    const closeDragElement = () => {
        document.onmouseup = null;
        document.onmousemove = null;
    };

    onMouseDown(event);
}
</script>


</body>
</html>
